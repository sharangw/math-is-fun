{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn import datasets, linear_model\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stops</th>\n",
       "      <th>pop</th>\n",
       "      <th>past.arrests</th>\n",
       "      <th>precinct</th>\n",
       "      <th>eth</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>1720</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>1720</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>1720</td>\n",
       "      <td>599</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1720</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stops   pop  past.arrests  precinct  eth  crime\n",
       "0     75  1720           191         1    1      1\n",
       "1     36  1720            57         1    1      2\n",
       "2     74  1720           599         1    1      3\n",
       "3     17  1720           133         1    1      4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nyc= pd.read_csv('NYC_stop_and_frisk.dat', sep='\\s+',skiprows=5)\n",
    "df_nyc.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.2 : What fraction of the total stops correspond to \\white/back/hispanic? What fraction of the population corresponds to \\white/black/hispanic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The white stops are :0.12915842337543754\n",
      "The black stops are :0.5312966063004109\n",
      "The hispanic stops are :0.3395449703241516\n"
     ]
    }
   ],
   "source": [
    "total= df_nyc.sum()[0]\n",
    "whiteStops = df_nyc[df_nyc['eth']==3].sum()[0]\n",
    "hispanicStops = df_nyc[df_nyc['eth']==2].sum()[0]\n",
    "blackStops = df_nyc[df_nyc['eth']==1].sum()[0]\n",
    "white_s = whiteStops /total\n",
    "black_s = blackStops /total\n",
    "hispanic_s = hispanicStops /total\n",
    "print(\"The white stops are :\"+ str(white_s))\n",
    "print(\"The black stops are :\"+ str(black_s))\n",
    "print(\"The hispanic stops are :\"+ str(hispanic_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.3: Use a Poisson regression to model the number of stops, controlling for ethnicity and using the number of past arrests as an exposure input.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_dummies = pd.get_dummies(df_nyc['eth'])\n",
    "df_nyc_new = pd.concat([df_nyc,eth_dummies],axis = 1)\n",
    "df_nyc_new =df_nyc_new.rename(columns={1:\"Black\",2:\"Hispanic\",3:\"White\",\"past.arrests\": \"Past_arrests\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  stops   No. Observations:                  900\n",
      "Model:                            GLM   Df Residuals:                      896\n",
      "Model Family:                 Poisson   Df Model:                            3\n",
      "Link Function:                    log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -94260.\n",
      "Date:                Thu, 17 Oct 2019   Deviance:                   1.8318e+05\n",
      "Time:                        23:01:21   Pearson chi2:                 2.79e+05\n",
      "No. Iterations:                     6   Covariance Type:             nonrobust\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.4953      0.004   -131.435      0.000      -0.503      -0.488\n",
      "pop         8.991e-07    8.1e-08     11.102      0.000     7.4e-07    1.06e-06\n",
      "Black         -0.1319      0.004    -35.721      0.000      -0.139      -0.125\n",
      "Hispanic      -0.0586      0.004    -14.064      0.000      -0.067      -0.050\n",
      "White         -0.3049      0.006    -49.110      0.000      -0.317      -0.293\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "from patsy import dmatrices\n",
    "\n",
    "df_nyc_new['Past_arrests'].replace(0,1,inplace=True)\n",
    "# formula = \"\"\"stops ~ pop + Black + Hispanic +White\"\"\"\n",
    "formula = \"\"\"stops ~ pop + Black + Hispanic +White\"\"\"\n",
    "\n",
    "response, predictors = dmatrices(formula, df_nyc_new, return_type='dataframe')\n",
    "po_results = stats.GLM(response, predictors, family=stats.families.Poisson(), exposure=df_nyc_new['Past_arrests']).fit()\n",
    "print(po_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.4 : According to the output of your model, what fraction fewer or more stops does each ethnicity have with respect to the others, in proportion to arrest rates of the previous year? Note that you can just pick a baseline ethnicity and just compare everything to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  stops   No. Observations:                  900\n",
      "Model:                            GLM   Df Residuals:                      896\n",
      "Model Family:                 Poisson   Df Model:                            3\n",
      "Link Function:                    log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -94260.\n",
      "Date:                Thu, 17 Oct 2019   Deviance:                   1.8318e+05\n",
      "Time:                        23:01:21   Pearson chi2:                 2.79e+05\n",
      "No. Iterations:                     6   Covariance Type:             nonrobust\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.8002      0.009    -89.279      0.000      -0.818      -0.783\n",
      "pop         8.991e-07    8.1e-08     11.102      0.000     7.4e-07    1.06e-06\n",
      "Black          0.1729      0.009     20.055      0.000       0.156       0.190\n",
      "Hispanic       0.2463      0.009     27.005      0.000       0.228       0.264\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "## baseline white ethinicty\n",
    "from patsy import dmatrices\n",
    "\n",
    "df_nyc_new['Past_arrests'].replace(0,1,inplace=True)   \n",
    "# formula = \"\"\"stops ~ pop + Black + Hispanic +White\"\"\" \n",
    "## remove white ethinicity\n",
    "formula = \"\"\"stops ~ pop + Black + Hispanic\"\"\"\n",
    "\n",
    "response, predictors = dmatrices(formula, df_nyc_new, return_type='dataframe')\n",
    "po_results = stats.GLM(response, predictors, family=stats.families.Poisson(), exposure=df_nyc_new['Past_arrests']).fit()\n",
    "print(po_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html(po_results.summary().tables[1].as_html(),header=0,index_col=0)[0]\n",
    "black_coeff=df['coef'].values[2]\n",
    "hispanic_coeff=df['coef'].values[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping white as baseline:\n",
      "The black ethnicity has : 18.874722441765623% more stops\n",
      "The hispanic ethnicity has : 27.928330097003705% more stops\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "hispanic_expo  = math.exp(hispanic_coeff)\n",
    "black_expo = math.exp(black_coeff)\n",
    "black_percentage = (black_expo -1)*100\n",
    "hispanic_percentage = (hispanic_expo -1)*100\n",
    "\n",
    "print(\"Keeping white as baseline:\")\n",
    "print(\"The black ethnicity has : \"+ str(black_percentage) + \"% more stops\")\n",
    "print(\"The hispanic ethnicity has : \"+ str(hispanic_percentage)  + \"% more stops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.5: Next, add the 75 precincts, and again solve the Poisson regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  stops   No. Observations:                  900\n",
      "Model:                            GLM   Df Residuals:                      822\n",
      "Model Family:                 Poisson   Df Model:                           77\n",
      "Link Function:                    log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -72943.\n",
      "Date:                Thu, 17 Oct 2019   Deviance:                   1.4055e+05\n",
      "Time:                        23:01:21   Pearson chi2:                 2.15e+05\n",
      "No. Iterations:                     7   Covariance Type:             nonrobust\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               -1.1267      0.013    -83.858      0.000      -1.153      -1.100\n",
      "pop                   3.796e-06   1.42e-07     26.751      0.000    3.52e-06    4.07e-06\n",
      "Black                    0.5776      0.012     49.881      0.000       0.555       0.600\n",
      "Hispanic                 0.5650      0.011     50.422      0.000       0.543       0.587\n",
      "precinct_dummies[0]     -0.8198      0.051    -16.193      0.000      -0.919      -0.721\n",
      "precinct_dummies[1]     -0.9640      0.053    -18.088      0.000      -1.068      -0.860\n",
      "precinct_dummies[2]     -0.2856      0.025    -11.350      0.000      -0.335      -0.236\n",
      "precinct_dummies[3]      0.3517      0.027     13.163      0.000       0.299       0.404\n",
      "precinct_dummies[4]     -0.5726      0.025    -22.779      0.000      -0.622      -0.523\n",
      "precinct_dummies[5]      0.3253      0.028     11.619      0.000       0.270       0.380\n",
      "precinct_dummies[6]     -0.6513      0.039    -16.709      0.000      -0.728      -0.575\n",
      "precinct_dummies[7]     -1.2168      0.026    -47.703      0.000      -1.267      -1.167\n",
      "precinct_dummies[8]     -0.3646      0.059     -6.216      0.000      -0.480      -0.250\n",
      "precinct_dummies[9]     -0.4119      0.030    -13.946      0.000      -0.470      -0.354\n",
      "precinct_dummies[10]    -0.3711      0.035    -10.748      0.000      -0.439      -0.303\n",
      "precinct_dummies[11]     0.2773      0.033      8.285      0.000       0.212       0.343\n",
      "precinct_dummies[12]     0.1324      0.021      6.219      0.000       0.091       0.174\n",
      "precinct_dummies[13]    -0.2927      0.029    -10.045      0.000      -0.350      -0.236\n",
      "precinct_dummies[14]     0.1631      0.021      7.899      0.000       0.123       0.204\n",
      "precinct_dummies[15]    -0.0714      0.032     -2.223      0.026      -0.134      -0.008\n",
      "precinct_dummies[16]    -0.9770      0.032    -30.192      0.000      -1.040      -0.914\n",
      "precinct_dummies[17]    -0.7907      0.021    -38.319      0.000      -0.831      -0.750\n",
      "precinct_dummies[18]    -0.7125      0.028    -25.640      0.000      -0.767      -0.658\n",
      "precinct_dummies[19]    -0.9744      0.025    -38.673      0.000      -1.024      -0.925\n",
      "precinct_dummies[20]    -0.5954      0.025    -23.781      0.000      -0.644      -0.546\n",
      "precinct_dummies[21]     0.2529      0.016     15.805      0.000       0.222       0.284\n",
      "precinct_dummies[22]    -0.2824      0.021    -13.517      0.000      -0.323      -0.241\n",
      "precinct_dummies[23]     0.3951      0.020     20.153      0.000       0.357       0.434\n",
      "precinct_dummies[24]    -0.1614      0.017     -9.298      0.000      -0.195      -0.127\n",
      "precinct_dummies[25]    -1.1731      0.026    -45.883      0.000      -1.223      -1.123\n",
      "precinct_dummies[26]     1.0064      0.022     44.937      0.000       0.962       1.050\n",
      "precinct_dummies[27]    -1.7968      0.033    -54.088      0.000      -1.862      -1.732\n",
      "precinct_dummies[28]     0.0545      0.019      2.812      0.005       0.017       0.093\n",
      "precinct_dummies[29]    -0.3932      0.022    -18.216      0.000      -0.436      -0.351\n",
      "precinct_dummies[30]     0.7561      0.024     32.095      0.000       0.710       0.802\n",
      "precinct_dummies[31]     0.5001      0.031     16.207      0.000       0.440       0.561\n",
      "precinct_dummies[32]     0.1051      0.019      5.676      0.000       0.069       0.141\n",
      "precinct_dummies[33]     0.6227      0.019     32.782      0.000       0.585       0.660\n",
      "precinct_dummies[34]    -0.1304      0.037     -3.509      0.000      -0.203      -0.058\n",
      "precinct_dummies[35]     0.5926      0.029     20.217      0.000       0.535       0.650\n",
      "precinct_dummies[36]     0.5050      0.031     16.034      0.000       0.443       0.567\n",
      "precinct_dummies[37]     0.8273      0.024     35.171      0.000       0.781       0.873\n",
      "precinct_dummies[38]    -0.8550      0.026    -33.348      0.000      -0.905      -0.805\n",
      "precinct_dummies[39]     0.5917      0.034     17.371      0.000       0.525       0.658\n",
      "precinct_dummies[40]     1.0478      0.023     46.118      0.000       1.003       1.092\n",
      "precinct_dummies[41]     0.0281      0.020      1.414      0.157      -0.011       0.067\n",
      "precinct_dummies[42]    -0.5798      0.026    -22.643      0.000      -0.630      -0.530\n",
      "precinct_dummies[43]    -0.0984      0.025     -3.996      0.000      -0.147      -0.050\n",
      "precinct_dummies[44]    -0.2312      0.019    -12.018      0.000      -0.269      -0.194\n",
      "precinct_dummies[45]    -0.4282      0.018    -23.821      0.000      -0.463      -0.393\n",
      "precinct_dummies[46]     0.2732      0.032      8.658      0.000       0.211       0.335\n",
      "precinct_dummies[47]    -0.6983      0.026    -26.838      0.000      -0.749      -0.647\n",
      "precinct_dummies[48]     0.2532      0.031      8.170      0.000       0.192       0.314\n",
      "precinct_dummies[49]    -0.1345      0.019     -7.266      0.000      -0.171      -0.098\n",
      "precinct_dummies[50]    -0.6865      0.029    -23.748      0.000      -0.743      -0.630\n",
      "precinct_dummies[51]    -0.4976      0.022    -22.774      0.000      -0.540      -0.455\n",
      "precinct_dummies[52]    -0.2494      0.029     -8.674      0.000      -0.306      -0.193\n",
      "precinct_dummies[53]    -0.4534      0.032    -14.374      0.000      -0.515      -0.392\n",
      "precinct_dummies[54]    -0.4708      0.030    -15.947      0.000      -0.529      -0.413\n",
      "precinct_dummies[55]     0.0596      0.042      1.431      0.153      -0.022       0.141\n",
      "precinct_dummies[56]     0.6918      0.034     20.271      0.000       0.625       0.759\n",
      "precinct_dummies[57]     0.6517      0.019     33.436      0.000       0.614       0.690\n",
      "precinct_dummies[58]     0.1911      0.029      6.500      0.000       0.133       0.249\n",
      "precinct_dummies[59]    -0.1765      0.019     -9.387      0.000      -0.213      -0.140\n",
      "precinct_dummies[60]     0.3249      0.025     13.098      0.000       0.276       0.374\n",
      "precinct_dummies[61]     0.0833      0.026      3.248      0.001       0.033       0.134\n",
      "precinct_dummies[62]     0.4089      0.028     14.511      0.000       0.354       0.464\n",
      "precinct_dummies[63]     0.8119      0.027     29.955      0.000       0.759       0.865\n",
      "precinct_dummies[64]     1.0122      0.021     47.987      0.000       0.971       1.054\n",
      "precinct_dummies[65]     1.1257      0.019     60.558      0.000       1.089       1.162\n",
      "precinct_dummies[66]     0.2549      0.020     12.455      0.000       0.215       0.295\n",
      "precinct_dummies[67]     1.2826      0.030     42.720      0.000       1.224       1.341\n",
      "precinct_dummies[68]     0.8352      0.028     29.768      0.000       0.780       0.890\n",
      "precinct_dummies[69]    -0.1462      0.022     -6.593      0.000      -0.190      -0.103\n",
      "precinct_dummies[70]     0.5215      0.019     28.072      0.000       0.485       0.558\n",
      "precinct_dummies[71]     0.4754      0.017     27.772      0.000       0.442       0.509\n",
      "precinct_dummies[72]     0.0594      0.017      3.557      0.000       0.027       0.092\n",
      "precinct_dummies[73]     0.0528      0.028      1.862      0.063      -0.003       0.108\n",
      "precinct_dummies[74]     0.6840      0.055     12.341      0.000       0.575       0.793\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "precinct_dummies = pd.get_dummies(df_nyc['precinct'])\n",
    "df_precinct = pd.concat([df_nyc_new,precinct_dummies],axis = 1)\n",
    "df_precinct\n",
    "# df_new = pd.concat([df, df_x], axis=1)\n",
    "# df_nyc_new =df_nyc_new.rename(columns={1:\"Black\",2:\"Hispanic\",3:\"White\",\"past.arrests\": \"Past_arrests\"})\n",
    "\n",
    "# Taking white race as the baseline.\n",
    "\n",
    "df_precinct['Past_arrests'].replace(0,1,inplace=True)\n",
    "\n",
    "formula = \"\"\"stops ~ pop + Black + Hispanic + precinct_dummies\"\"\"\n",
    "\n",
    "response, predictors = dmatrices(formula, df_precinct, return_type='dataframe')\n",
    "po_results = stats.GLM(response, predictors, family=stats.families.Poisson(), exposure=df_precinct['Past_arrests']).fit()\n",
    "print(po_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.6 Now, controlling for precincts, according to your model, what fraction fewer or more stops  does each ethnicity have with respect to the others, in proportion to arrest rates of the  previous year? (Again, just report with respect to a chosen ethnicity as a baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.565"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.read_html(po_results.summary().tables[1].as_html(),header=0,index_col=0)[0]\n",
    "black_coeff=df6['coef'].values[2]\n",
    "hispanic_coeff=df6['coef'].values[3]\n",
    "hispanic_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping white as baseline:\n",
      "The black ethnicity has : 78.1757078194389% percentage more stops\n",
      "The hispanic ethnicity has : 75.9447782721815% percentage more stops\n"
     ]
    }
   ],
   "source": [
    "hispanic_expo  = math.exp(hispanic_coeff)\n",
    "black_expo = math.exp(black_coeff)\n",
    "black_percentage = (black_expo -1)*100\n",
    "hispanic_percentage = (hispanic_expo -1)*100\n",
    "\n",
    "print(\"Keeping white as baseline:\")\n",
    "print(\"The black ethnicity has : \"+ str(black_percentage) + \"% percentage more stops\")\n",
    "print(\"The hispanic ethnicity has : \"+ str(hispanic_percentage)  + \"% percentage more stops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba = pd.read_csv('nba_cc_fake_data.csv', sep=',')  ## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba.head()\n",
    "nba2 = nba.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba = nba2.rename(columns = {\"Unnamed: 0\":\"Id\"})  ## use a more readable field name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Comp</th>\n",
       "      <th>Height</th>\n",
       "      <th>Points</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Comp  Height  Points  Salary\n",
       "0   0   9.0    76.0    27.0     0.0\n",
       "1   1   7.0    78.0    39.0     0.0\n",
       "2   2   9.0    76.0    39.0     0.0\n",
       "3   3   9.0    74.0    39.0     0.0\n",
       "4   4   9.0    74.0    26.0     0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nba.loc[:,[\"Comp\",\"Height\",\"Points\"]].values\n",
    "y = nba.loc[:,[\"Salary\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression is not appropriate for this data because the salary, or the variable we are trying to predict, is not available for most of the points in the data. Therefore, there may or may not be any sort of association between the given explanatory variables and the outcome variable. It is thus hard to use linear regression to find a relationship between the two sets of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17136027274846133"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# least squares regression:\n",
    "OLS = LinearRegression()\n",
    "OLS.fit(X_train,y_train).predict(X_test)\n",
    "y_pred_OLS = OLS.fit(X_train, y_train).predict(X_test)\n",
    "r2_score_OLS = r2_score(y_test, y_pred_OLS)\n",
    "r2_score_OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Composite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for salary dummy variable: 1 if player has a salary, 0 otherwise\n",
    "nba[\"salary_dummy\"] = np.where(nba[\"Salary\"] > 0 , 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LR = nba.loc[:,[\"Comp\", \"Height\", \"Points\"]].values\n",
    "y_LR = nba.loc[:,[\"salary_dummy\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% of data are training data and 20% are test data\n",
    "X_train_LR, X_test_LR, y_train_LR, y_test_LR = train_test_split(X_LR, y_LR, test_size = .2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg = LogisticRegression(fit_intercept = True)\n",
    "LogReg.fit(X_train_LR,y_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_LR = LogReg.predict_proba(X_test_LR)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computed AUC on the test set: 0.9116361551965034\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_true = y_test_LR, y_score = y_predict_LR)\n",
    "print(\"The computed AUC on the test set: \" + str(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(fit_intercept = True)\n",
    "LogReg.fit(X_train_LR, y_train_LR)\n",
    "\n",
    "clf2 = LinearRegression()  \n",
    "OLS.fit(X_train, y_train)\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers = [clf1, clf2], meta_classifier = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclf.fit(X_train_LR,y_train_LR)\n",
    "y_predict = sclf.predict_proba(X_test_LR)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared score for the composite model: 0.33297111106003296\n"
     ]
    }
   ],
   "source": [
    "r2_score_sclf = r2_score(y_test_LR, y_predict)\n",
    "print(\"The R-squared score for the composite model: \" + str(r2_score_sclf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 - Predict Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "a = np.array([9,78,46]) # comp: 9, 78 inches, 46 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ex = a.reshape(-1,3) # get a 1 row by 3 columns array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93780953, 0.06219047]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = LogReg.predict_proba(X_test_ex)  # LR model predicting whether or not player gets in NBA\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of this player making it to the NBA is: 0.06219047131859633\n"
     ]
    }
   ],
   "source": [
    "print(\"The probability of this player making it to the NBA is: \" + str(y_predict[0][1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6542.515653]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_salary = OLS.predict(X_test_ex) \n",
    "expected_salary = expected_salary*y_predict[0][1]\n",
    "expected_salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### According to our model, the predicted salary for a high school basketball player who is 6' 6\" tall, is averaging 46 points per game, and is playing in the second most competitive league is \\$6542.52"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
